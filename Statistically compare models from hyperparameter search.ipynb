{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4aac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "from math import factorial\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import shap\n",
    "from alibi.explainers import KernelShap\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21f5e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparameter_scores( search ):\n",
    "    results_df = pd.DataFrame(search.cv_results_)\n",
    "    results_df = results_df.sort_values(by=[\"rank_test_score\"])\n",
    "    results_df = results_df.set_index(\n",
    "        results_df[\"params\"].apply(lambda x: \"_\".join(str(val) for val in x.values()))\n",
    "    ).rename_axis(\"kernel\")\n",
    "    \n",
    "    return results_df[[\"params\", \"rank_test_score\", \"mean_test_score\", \"std_test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ae5083",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X, y = load_iris( return_X_y = True )\n",
    "\n",
    "scaler   = StandardScaler().fit( X )\n",
    "X_normed = scaler.transform( X )\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split( X_normed, y, train_size = 0.75, test_size = .25, random_state = 0 )\n",
    "\n",
    "cv = RepeatedStratifiedKFold( n_splits = 10, n_repeats = 10, random_state = 0 ) # A 10x 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142b2f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_as = BayesSearchCV(\n",
    "                        SVC(),\n",
    "                        {\n",
    "                            'C': (1e-6, 1e+6, 'log-uniform'),\n",
    "                            'gamma': (1e-6, 1e+1, 'log-uniform'),\n",
    "                            'degree': (1, 8),  # integer valued parameter\n",
    "                            'kernel': ['linear', 'poly', 'rbf'],  # categorical parameter\n",
    "                        },\n",
    "                        n_iter=10,\n",
    "                        cv = cv\n",
    "                     )\n",
    "\n",
    "svc_as.fit( Xtrain, ytrain )\n",
    "\n",
    "print(\"params    : %s\" % svc_as.best_params_)\n",
    "print(\"val. score: %s\" % svc_as.best_score_)\n",
    "print(\"test score: %s\" % svc_as.score(Xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb257bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "random_state = check_random_state( 0 )\n",
    "permutation  = random_state.permutation( X.shape[ 0 ] )\n",
    "\n",
    "X = X[ permutation ]\n",
    "y = y[ permutation ]\n",
    "X = X.reshape( ( X.shape[ 0 ], -1 ) )\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split( X, y, train_size = train_samples, test_size = test_samples )\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xtrain = scaler.fit_transform( Xtrain )\n",
    "Xtest  = scaler.transform( Xtest )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ad307",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_rs = RandomizedSearchCV( \n",
    "                            SVC(), \n",
    "                            {\n",
    "                              'C'     : stats.loguniform(1e-6, 1e+6),\n",
    "                              'gamma' : stats.loguniform(1e-6, 1e+1),\n",
    "                              'degree': stats.randint(1, 8),         \n",
    "                              'kernel': ['linear', 'poly', 'rbf'], \n",
    "                            }, \n",
    "                            n_iter = 10, \n",
    "                            cv = cv, \n",
    "                            n_jobs = 6 )\n",
    "svc_rs.fit( Xtrain, ytrain )\n",
    "\n",
    "print(\"params    : %s\" % svc_rs.best_params_)\n",
    "print(\"val. score: %s\" % svc_rs.best_score_)\n",
    "print(\"test score: %s\" % svc_rs.score(Xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc362b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_gs = GridSearchCV( \n",
    "                       SVC(), \n",
    "                       {\n",
    "                         'C'     : np.power(10, np.arange(-4, 1, dtype=float)),\n",
    "                         'gamma' : np.power(10, np.arange(-4, 1, dtype=float)),\n",
    "                         'degree': np.arange(1, 9, dtype = int ),         \n",
    "                         'kernel': ['linear', 'poly', 'rbf'], \n",
    "                       }, \n",
    "                       cv = cv, \n",
    "                       n_jobs = 6 )\n",
    "\n",
    "svc_gs.fit( Xtrain, ytrain )\n",
    "\n",
    "print(\"params    : %s\" % svc_gs.best_params_)\n",
    "print(\"val. score: %s\" % svc_gs.best_score_)\n",
    "print(\"test score: %s\" % svc_gs.score(Xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f02c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_as = BayesSearchCV(\n",
    "                        LogisticRegression(),\n",
    "                        {\n",
    "                            'C': (1e-6, 1e+6, 'log-uniform'),\n",
    "                            'tol': (1e-6, 1e+1, 'log-uniform'),\n",
    "                            'max_iter': (100, 400),  \n",
    "                            'solver': ['sag', 'saga', 'newton-cg'],\n",
    "                        },\n",
    "                        n_iter=10,\n",
    "                        cv = cv\n",
    "                     )\n",
    "\n",
    "lgr_as.fit( Xtrain, ytrain )\n",
    "\n",
    "print(\"params    : %s\" % lgr_as.best_params_)\n",
    "print(\"val. score: %s\" % lgr_as.best_score_)\n",
    "print(\"test score: %s\" % lgr_as.score(Xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c783e520",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_rs = RandomizedSearchCV(\n",
    "                        LogisticRegression(),\n",
    "                        {\n",
    "                            'C':   stats.loguniform(1e-6, 1e+6),\n",
    "                            'tol': stats.loguniform(1e-6, 1e+6),\n",
    "                            'max_iter': stats.randint(100, 400),  # integer valued parameter\n",
    "                            'solver': ['sag', 'saga', 'newton-cg'],  # categorical parameter\n",
    "                        },\n",
    "                        n_iter=10,\n",
    "                        cv = cv\n",
    "                     )\n",
    "\n",
    "lgr_rs.fit(Xtrain, ytrain)\n",
    "\n",
    "print(\"params    : %s\" % lgr_rs.best_params_)\n",
    "print(\"val. score: %s\" % lgr_rs.best_score_)\n",
    "print(\"test score: %s\" % lgr_rs.score(Xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_gs = GridSearchCV(\n",
    "                        LogisticRegression(),\n",
    "                        {\n",
    "                            'C'       : np.power(10, np.arange(-4, 1, dtype=float)),\n",
    "                            'tol'     : np.power(10, np.arange(-4, 1, dtype=float)),\n",
    "                            'max_iter': np.arange(100, 450, 50, dtype = int ),  # integer valued parameter\n",
    "                            'solver': ['sag', 'saga', 'newton-cg'],  # categorical parameter\n",
    "                        },\n",
    "                        cv = cv\n",
    "                     )\n",
    "\n",
    "lgr_gs.fit(Xtrain, ytrain)\n",
    "\n",
    "print(\"params    : %s\" % lgr_gs.best_params_)\n",
    "print(\"val. score: %s\" % lgr_gs.best_score_)\n",
    "print(\"test score: %s\" % lgr_gs.score(Xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23ed0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_gs_df = get_hyperparameter_scores( svc_gs )\n",
    "svc_rs_df = get_hyperparameter_scores( svc_rs )\n",
    "svc_as_df = get_hyperparameter_scores( svc_as )\n",
    "\n",
    "svc_scores = pd.concat( [ svc_gs_df.head( 1 ), svc_rs_df.head( 1 ), svc_as_df.head( 1 ) ] )\n",
    "\n",
    "svc_scores.rename( index = { svc_scores.index[ 0 ]: 'SVC-GS', \n",
    "                             svc_scores.index[ 1 ]: 'SVC-RS',\n",
    "                             svc_scores.index[ 2 ]: 'SVC-AS'\n",
    "                           } \n",
    "                  ,inplace = True \n",
    "                 )\n",
    "\n",
    "svc_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b988c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_as_df  = get_hyperparameter_scores( lgr_as )\n",
    "lgr_rs_df  = get_hyperparameter_scores( lgr_rs )\n",
    "lgr_gs_df  = get_hyperparameter_scores( lgr_gs )\n",
    "\n",
    "lgr_scores = pd.concat( [ lgr_gs_df.head( 1 ), lgr_rs_df.head( 1 ), lgr_as_df.head( 1 ) ] )\n",
    "\n",
    "lgr_scores.rename( index = { lgr_scores.index[ 0 ]: 'LGR-GS', \n",
    "                             lgr_scores.index[ 1 ]: 'LGR-RS',\n",
    "                             lgr_scores.index[ 2 ]: 'LGR-AS'\n",
    "                           } \n",
    "                 , inplace = True )\n",
    "lgr_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8796547",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scores = pd.concat( [ svc_scores, lgr_scores ] )\n",
    "result_scores.head( 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eefa594",
   "metadata": {},
   "outputs": [],
   "source": [
    "a             = 0.01\n",
    "rope_interval = [-a, a]\n",
    "\n",
    "n_train = len(list(cv.split(Xtrain, ytrain))[0][0])\n",
    "n_test  = len(list(cv.split(Xtrain, ytrain))[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "\n",
    "def corrected_std(differences, n_train, n_test):\n",
    "    \"\"\"Corrects standard deviation using Nadeau and Bengio's approach.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    differences : ndarray of shape (n_samples,)\n",
    "        Vector containing the differences in the score metrics of two models.\n",
    "    n_train : int\n",
    "        Number of samples in the training set.\n",
    "    n_test : int\n",
    "        Number of samples in the testing set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    corrected_std : float\n",
    "        Variance-corrected standard deviation of the set of differences.\n",
    "    \"\"\"\n",
    "    # kr = k times r, r times repeated k-fold crossvalidation,\n",
    "    # kr equals the number of times the model was evaluated\n",
    "    kr = len(differences)\n",
    "    corrected_var = np.var(differences, ddof=1) * (1 / kr + n_test / n_train)\n",
    "    corrected_std = np.sqrt(corrected_var)\n",
    "    return corrected_std\n",
    "\n",
    "\n",
    "def compute_corrected_ttest(differences, df, n_train, n_test):\n",
    "    \"\"\"Computes right-tailed paired t-test with corrected variance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    differences : array-like of shape (n_samples,)\n",
    "        Vector containing the differences in the score metrics of two models.\n",
    "    df : int\n",
    "        Degrees of freedom.\n",
    "    n_train : int\n",
    "        Number of samples in the training set.\n",
    "    n_test : int\n",
    "        Number of samples in the testing set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    t_stat : float\n",
    "        Variance-corrected t-statistic.\n",
    "    p_val : float\n",
    "        Variance-corrected p-value.\n",
    "    \"\"\"\n",
    "    mean = np.mean(differences)\n",
    "    std = corrected_std(differences, n_train, n_test)\n",
    "    t_stat = mean / std\n",
    "    p_val = t.sf(np.abs(t_stat), df)  # right-tailed t-test\n",
    "    return t_stat, p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a46510",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = result_scores.copy()\n",
    "model_scores = model_scores[ [ 'mean_test_score', 'std_test_score' ] ]\n",
    "model_scores.head( 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8584e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_bayesian = []\n",
    "\n",
    "for model_i, model_k in combinations(range(len(model_scores)), 2):\n",
    "    model_i_scores = model_scores.iloc[model_i].values\n",
    "    model_k_scores = model_scores.iloc[model_k].values\n",
    "    differences = model_i_scores - model_k_scores\n",
    "    t_post = t(\n",
    "        differences.shape[ 0 ] - 1, loc=np.mean(differences), scale=corrected_std(differences, n_train, n_test)\n",
    "    )\n",
    "    worse_prob = t_post.cdf(rope_interval[0])\n",
    "    better_prob = 1 - t_post.cdf(rope_interval[1])\n",
    "    rope_prob = t_post.cdf(rope_interval[1]) - t_post.cdf(rope_interval[0])\n",
    "\n",
    "    pairwise_bayesian.append([model_scores.index[model_i], model_scores.index[model_k],\n",
    "                              worse_prob, better_prob, rope_prob])\n",
    "\n",
    "pairwise_bayesian_df = pd.DataFrame(\n",
    "    pairwise_bayesian, columns=[ \"model_1\", \"model_2\", \"worse_prob\", \"better_prob\", \"rope_prob\"]\n",
    ").round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e8792",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_bayesian_df.sort_values( by = [ 'better_prob' ], ascending = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e2469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression( C        = lgr_gs.best_params_[ 'C' ],\n",
    "                          max_iter = lgr_gs.best_params_[ 'max_iter' ],\n",
    "                          solver   = lgr_gs.best_params_[ 'solver' ],\n",
    "                          tol      = lgr_gs.best_params_[ 'tol' ]\n",
    "                        ) \n",
    "lgr.fit( Xtrain, ytrain )\n",
    "\n",
    "y_pred = lgr.predict( Xtest )\n",
    "\n",
    "cm = confusion_matrix( ytest, y_pred )\n",
    "title = 'Confusion matrix for Logistic Regression'\n",
    "disp = plot_confusion_matrix(lgr,\n",
    "                             Xtest,\n",
    "                             ytest,\n",
    "                             display_labels = iris.target_names,\n",
    "                             cmap           = plt.cm.Blues,\n",
    "                             normalize      = None,\n",
    "                            )\n",
    "disp.ax_.set_title( title );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47063486",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fn = lgr.decision_function\n",
    "np.random.seed( 0 )\n",
    "lgr_exp = KernelShap( pred_fn )\n",
    "lgr_exp.fit( Xtrain )\n",
    "lgr_shap_vals = lgr_exp.explain( Xtest, l1_reg = False )\n",
    "\n",
    "shap.summary_plot( lgr_shap_vals.shap_values, Xtest, iris.feature_names, class_names = iris.target_names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6024232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC( C      = svc_rs.best_params_[ 'C' ],\n",
    "           degree = svc_rs.best_params_[ 'degree' ],\n",
    "           gamma  = svc_rs.best_params_[ 'gamma' ],\n",
    "           kernel = svc_rs.best_params_[ 'kernel' ]\n",
    "         )\n",
    "\n",
    "svc.fit( Xtrain, ytrain )\n",
    "\n",
    "y_pred = lgr.predict( Xtest )\n",
    "\n",
    "cm = confusion_matrix( ytest, y_pred )\n",
    "title = 'Confusion matrix for SVM'\n",
    "disp = plot_confusion_matrix(svc,\n",
    "                             Xtest,\n",
    "                             ytest,\n",
    "                             display_labels = iris.target_names,\n",
    "                             cmap           = plt.cm.Blues,\n",
    "                             normalize      = None,\n",
    "                            )\n",
    "disp.ax_.set_title( title );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dd3599",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fn = svc.decision_function\n",
    "np.random.seed( 0 )\n",
    "svc_exp = KernelShap( pred_fn )\n",
    "svc_exp.fit( Xtrain )\n",
    "svc_shap_vals = svc_exp.explain( Xtest, l1_reg = False )\n",
    "\n",
    "shap.summary_plot( svc_shap_vals.shap_values, Xtest, iris.feature_names, class_names = iris.target_names )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
